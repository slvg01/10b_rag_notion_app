{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "\n",
    "# Read the configuration file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../config.ini')\n",
    "\n",
    "# Access the API token from the configuration file\n",
    "huggingfacehub_api_token = config.get('huggingface', 'api_token')\n",
    "# Set your API Key from OpenAI\n",
    "openai_api_key = config.get('openai', 'api_key')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Coding with BeCode\\nLearning skills for the future\\nTech world at our feet' response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 24, 'total_tokens': 40}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3b956da36b', 'finish_reason': 'stop', 'logprobs': None} id='run-30beb457-e712-4c85-94c8-1ed7340ec38d-0'\n"
     ]
    }
   ],
   "source": [
    "#basics chain sequence using LCEL\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=openai_api_key)\n",
    "prompt = ChatPromptTemplate.from_template(\"You are a skilled poet. Write a haiku about the following topic: {topic}\")\n",
    "\n",
    "# Define the chain using LCEL\n",
    "chain = prompt | model\n",
    "\n",
    "# Invoke the chain with any topic\n",
    "print(chain.invoke({\"topic\": \"Becode\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Pink sun', response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 78, 'total_tokens': 80}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3b956da36b', 'finish_reason': 'stop', 'logprobs': None}, id='run-db9434b5-7495-4af5-8e50-ab8b741f619c-0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same but with passthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Create the retriever and model\n",
    "vectorstore = Chroma.from_texts([\"the fish is pink like a sun.\"], embedding=OpenAIEmbeddings(openai_api_key=openai_api_key))\n",
    "retriever = vectorstore.as_retriever()\n",
    "model = ChatOpenAI(openai_api_key=openai_api_key, temperature=0)\n",
    "\n",
    "template = \"\"\"Answer the question based on the context:{context}. Question: {question}\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Create the chain and run it\n",
    "chain = (\n",
    "  {\"context\": retriever, \"question\":RunnablePassthrough()}\n",
    "  | prompt\n",
    "  | model)\n",
    "\n",
    "chain.invoke(\"how the fish looks like, in 2 words?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```python\\nmy_list = [3, 1, 4, 1]\\n\\n[element for element in my_list]\\n```'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# longer chain example \n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "coding_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Write Python code to loop through the following list, printing each element: {list}\"\"\")\n",
    "validate_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Consider the following Python code: {answer} If it doesn't use a list comprehension, update it to use one. If it does use a list comprehension, return the original code without explanation:\"\"\")\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=openai_api_key)\n",
    "\n",
    "# Create the sequential chain\n",
    "chain = ({\"answer\": coding_prompt | llm |StrOutputParser()}\n",
    "         | validate_prompt\n",
    "         | llm \n",
    "         | StrOutputParser() )\n",
    "\n",
    "# Invoke the chain with the user's question\n",
    "chain.invoke({\"list\": \"[3, 1, 4, 1]\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With our app, users can type faster and more accurately than ever before, thanks to our advanced predictive text technology and customizable keyboard layouts. We have conducted extensive market research to understand the needs and preferences of mobile users, and have tailored our app to meet those needs.\n",
      "\n",
      "Our business plan outlines a clear path to profitability, with multiple revenue streams including in-app purchases, premium features, and partnerships with mobile device manufacturers. We have also developed a comprehensive marketing strategy to drive user acquisition and retention, including targeted advertising, social media campaigns, and influencer partnerships.\n",
      "\n",
      "Through strategic implementation of our app, we aim to achieve widespread adoption and become the go-to virtual keyboard for mobile users worldwide. With a focus on user experience, innovation, and scalability, we are confident that our app will revolutionize typing on mobile touchscreens and disrupt the virtual keyboard market.\n"
     ]
    }
   ],
   "source": [
    "# full integrated chain chatbot like \n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Make ceo_response available for other chains\n",
    "ceo_response = (\n",
    "    ChatPromptTemplate.from_template(\"You are a CEO. Describe the most lucrative consumer product addressing the following consumer need in one sentence: {input}.\")\n",
    "    | ChatOpenAI(openai_api_key=openai_api_key)\n",
    "    | {\"ceo_response\": RunnablePassthrough() | StrOutputParser()}\n",
    ")\n",
    "\n",
    "advisor_response = (\n",
    "    ChatPromptTemplate.from_template(\"You are a strategic adviser. Briefly map the outline and business plan for {ceo_response} in 3 key steps.\")\n",
    "    | ChatOpenAI(openai_api_key=openai_api_key)\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "overall_response = (\n",
    "    ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"human\", \"CEO response:\\n{ceo_response}\\n\\nAdvisor response:\\n{advisor_response}\"),\n",
    "            (\"system\", \"Generate a final response including the CEO's response, the advisor response, and a summary of the business plan in one sentence.\"),\n",
    "        ]\n",
    "    )\n",
    "    | ChatOpenAI(openai_api_key=openai_api_key)\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "#Â Create a chain to insert the outputs from the other chains into overall_response\n",
    "business_idea_chain = (\n",
    "    {\"ceo_response\": ceo_response, \"advisor_response\": advisor_response}\n",
    "    | overall_response\n",
    "    | ChatOpenAI(openai_api_key=openai_api_key)\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(business_idea_chain.invoke({\"input\": \"Typing on mobile touchscreens is slow.\", \"ceo_response\": \"\", \"advisor_response\": \"\"}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
